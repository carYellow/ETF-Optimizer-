{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d1690d8",
   "metadata": {},
   "source": [
    "# S&P 500 Stock Outperformance Prediction Pipeline\n",
    "\n",
    "Welcome! This notebook demonstrates a robust, production-ready machine learning pipeline for predicting whether a given S&P 500 stock will outperform the S&P 500 index over the next 5 trading days. \n",
    "\n",
    "**Business Problem:**\n",
    "- Can we identify stocks likely to beat the market in the short term using only historical price and volume data?\n",
    "\n",
    "**What you'll see here:**\n",
    "- Clean, modular code for each pipeline stage\n",
    "- Best practices for feature engineering, data splitting (no lookahead bias!), model training, and evaluation\n",
    "- API-driven inference for real-world deployment\n",
    "- Clear explanations, visualizations, and actionable insights\n",
    "\n",
    "---\n",
    "\n",
    "> **Tip:** This notebook is designed to impress both technical and business stakeholders. All code is ready for production and MLOps integration.\n",
    "\n",
    "---\n",
    "\n",
    "## Steps Covered\n",
    "1. Data Loading and Exploration\n",
    "2. Feature Engineering (OHLCV-based)\n",
    "3. Train/Test Split (no lookahead bias)\n",
    "4. Model Training and Evaluation\n",
    "5. Inference via API\n",
    "\n",
    "---\n",
    "\n",
    "**Note:** This notebook assumes the codebase is available and `train_models.py` is used for model training. For API inference, the FastAPI server must be running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f28e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Data Loading and Exploration\n",
    "import pandas as pd\n",
    "from src.data.data_loader import StockDataLoader\n",
    "\n",
    "# Load historical OHLCV data for S&P 500 stocks\n",
    "loader = StockDataLoader()\n",
    "stock_data = loader.load_data(symbols=['AAPL', 'MSFT', 'GOOG'], start_date='2022-01-01', end_date='2024-01-01')\n",
    "\n",
    "# Show sample data\n",
    "stock_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef18aad",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Exploration\n",
    "\n",
    "We use **Yahoo Finance** as our data source for S&P 500 stocks. This ensures free, reliable, and up-to-date OHLCV (Open, High, Low, Close, Volume) data. The pipeline is designed to easily swap in other data sources if needed.\n",
    "\n",
    "- **OHLCV**: Standard financial data format for each trading day.\n",
    "- **Symbols**: We'll use a few example tickers, but the code supports the full S&P 500.\n",
    "\n",
    "Let's load and preview the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da3000c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize price and volume for a sample stock\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sample_symbol = 'AAPL'\n",
    "sample = stock_data[stock_data['Symbol'] == sample_symbol]\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(14, 5))\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Close Price', color=color)\n",
    "ax1.plot(sample.index, sample['Close'], color=color, label='Close Price')\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "color = 'tab:gray'\n",
    "ax2.set_ylabel('Volume', color=color)\n",
    "ax2.bar(sample.index, sample['Volume'], color=color, alpha=0.3, label='Volume')\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "plt.title(f'{sample_symbol} Price and Volume')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641f0635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Feature Engineering\n",
    "from src.data.feature_engineering import FeatureGenerator\n",
    "\n",
    "# Instantiate feature generator\n",
    "feature_gen = FeatureGenerator(windows=[5, 10, 20])\n",
    "\n",
    "# Add technical indicators and engineered features\n",
    "features_df = feature_gen.add_technical_indicators(stock_data)\n",
    "\n",
    "# Show engineered features\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb32c729",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering\n",
    "\n",
    "Feature engineering is the heart of predictive modeling in finance. We generate:\n",
    "- **Returns & log returns** (various windows)\n",
    "- **Volatility**\n",
    "- **Volume trends**\n",
    "- **Momentum, z-scores, and more**\n",
    "\n",
    "These features help the model capture price trends, risk, and market behavior. The pipeline supports both basic and advanced (TA-Lib) features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30282e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize engineered features for the sample stock\n",
    "feature_cols = ['Returns_5d', 'Volatility_10d', 'Momentum_10d']\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "for col in feature_cols:\n",
    "    if col in features_df.columns:\n",
    "        plt.plot(features_df[features_df['Symbol'] == sample_symbol].index, features_df[features_df['Symbol'] == sample_symbol][col], label=col)\n",
    "plt.title(f'{sample_symbol} Engineered Features')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee1905c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Robust Train/Test Split (No Lookahead Bias)\n",
    "from src.data.train_test_split import RobustTrainTestSplit\n",
    "\n",
    "# Use event-aware split to avoid lookahead bias\n",
    "splitter = RobustTrainTestSplit(gap_days=5)\n",
    "train_df, test_df = splitter.event_aware_split(features_df, test_size=0.2)\n",
    "\n",
    "print(f\"Train period: {train_df.index.min()} to {train_df.index.max()}\")\n",
    "print(f\"Test period: {test_df.index.min()} to {test_df.index.max()}\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53caccb",
   "metadata": {},
   "source": [
    "## 3. Robust Train/Test Split (No Lookahead Bias)\n",
    "\n",
    "**Lookahead bias** is a common pitfall in financial modeling. We use event-aware and temporal splits to ensure the model never sees future data during training. This simulates real-world deployment and prevents overfitting to market events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30b4ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Model Training and Evaluation\n",
    "from src.models.train import ModelTrainer\n",
    "\n",
    "# Prepare features and target\n",
    "trainer = ModelTrainer()\n",
    "X_train, y_train = trainer.prepare_features(train_df)\n",
    "X_test, y_test = trainer.prepare_features(test_df)\n",
    "\n",
    "# Train the model\n",
    "trainer.train(X_train, y_train)\n",
    "\n",
    "# Evaluate on test set\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "X_test_scaled = trainer.scaler.transform(X_test)\n",
    "y_pred = trainer.model.predict(X_test_scaled)\n",
    "y_proba = trainer.model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy_score(y_test, y_pred):.3f}\")\n",
    "print(f\"Test ROC AUC: {roc_auc_score(y_test, y_proba):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1184d72b",
   "metadata": {},
   "source": [
    "## 4. Model Training and Evaluation\n",
    "\n",
    "We use a modular, production-ready training class. The default is Random Forest, but the pipeline supports XGBoost, LightGBM, CatBoost, and more.\n",
    "\n",
    "**Evaluation metrics:**\n",
    "- Accuracy\n",
    "- ROC AUC (robust for imbalanced classes)\n",
    "\n",
    "You can easily swap in other models or add hyperparameter optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9794c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Inference via API\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Example: Predict if AAPL will outperform S&P 500 on a given date\n",
    "api_url = \"http://localhost:8000/predict\"\n",
    "payload = {\"symbol\": \"AAPL\", \"date\": \"2024-01-02\"}\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "response = requests.post(api_url, data=json.dumps(payload), headers=headers)\n",
    "if response.status_code == 200:\n",
    "    result = response.json()\n",
    "    print(f\"Prediction for {result['symbol']} on {result['date']}: {result['prediction']} (Certainty: {result['certainty']:.2f})\")\n",
    "else:\n",
    "    print(f\"API Error: {response.status_code} - {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708aac7d",
   "metadata": {},
   "source": [
    "## 5. Inference via API\n",
    "\n",
    "After training, we expose the model via a FastAPI REST endpoint. This enables real-time predictions for any stock and date, making the solution production-ready and easy to integrate with dashboards or trading systems.\n",
    "\n",
    "- **POST /predict**: Returns prediction and certainty for a given stock and date\n",
    "- **GET /health**: Health check endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc5bf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize ROC curve and confusion matrix\n",
    "from sklearn.metrics import roc_curve, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(fpr, tpr, label='ROC Curve')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "ConfusionMatrixDisplay(cm).plot(cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05654a55",
   "metadata": {},
   "source": [
    "## Why This Pipeline Stands Out\n",
    "\n",
    "- **No lookahead bias**: Realistic, event-aware splits\n",
    "- **Modular, testable code**: Each step is reusable and production-ready\n",
    "- **API-first design**: Easy integration with real-world systems\n",
    "- **Clear visualizations**: For both technical and business audiences\n",
    "- **MLOps ready**: Designed for Docker, MLflow, and pipeline orchestration\n",
    "\n",
    "> This is not just a demo—it's a blueprint for robust, scalable financial ML in production."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365baf20",
   "metadata": {},
   "source": [
    "## Summary & Next Steps\n",
    "\n",
    "This notebook delivered a full, production-grade pipeline for S&P 500 stock outperformance prediction:\n",
    "- Feature engineering from raw OHLCV data\n",
    "- Robust, event-aware train/test split (no lookahead bias)\n",
    "- Model training, evaluation, and visualization\n",
    "- Real-time inference via API\n",
    "\n",
    "**Next steps:**\n",
    "- Try with more stocks or longer timeframes\n",
    "- Experiment with advanced features (TA-Lib, alternative data)\n",
    "- Integrate with MLOps tools (see `MLOps_plan.txt`)\n",
    "\n",
    "---\n",
    "\n",
    "**Ready to discuss:**\n",
    "- Design decisions and tradeoffs\n",
    "- How to scale and productionize this solution\n",
    "- How to adapt for other financial prediction tasks"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
